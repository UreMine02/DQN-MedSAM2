agent:
  _target_: sam2_train.rl_modules.policy_optimization.ppo_agent.PPOAgent
  num_maskmem: 6
  policy_lr: 1e-4
  value_lr: 1e-4
  gamma: 0.99
  buffer_size: 100
  batch_size: 4
  entropy_weight: 0.1
  epsilon: 0.2
  tau: 1
  sam2_dim:
    n_query: 16
    image_dim: 256
    memory_dim: 64
    obj_ptr_dim: 256