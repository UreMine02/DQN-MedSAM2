{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29568093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2096b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "impath = \"/data/datasets/BTCV/imagesTr/img0001.nii.gz\"\n",
    "gtpath = \"/data/datasets/BTCV/labelsTr/img0001.nii.gz\"\n",
    "timpath = \"/data/datasets/Sarcoma/imagesTr/STS_001_Edema.nii.gz\"\n",
    "tgtpath = \"/data/datasets/Sarcoma/labelsTr/STS_001_Edema.nii.gz\"\n",
    "im_raw = nib.load(impath)\n",
    "gt_raw = nib.load(gtpath)\n",
    "tim_raw = nib.load(timpath)\n",
    "tgt_raw = nib.load(tgtpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc941731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = np.array(gt_raw.dataobj)\n",
    "np.unique(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9d9a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.asanyarray(im_raw.dataobj)\n",
    "gt = np.asanyarray(gt_raw.dataobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(gt.sum(axis=(0,1))).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37516cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im[:, :, 52], cmap=\"grey\")\n",
    "plt.imshow(gt[:, :, 52], alpha=0.6, cmap=\"jet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cec8b987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maskmem_tpos_enc\n",
      "no_mem_embed\n",
      "no_mem_pos_enc\n",
      "no_obj_ptr\n",
      "image_encoder.trunk.pos_embed\n",
      "image_encoder.trunk.pos_embed_window\n",
      "image_encoder.trunk.patch_embed.proj.weight\n",
      "image_encoder.trunk.patch_embed.proj.bias\n",
      "image_encoder.trunk.blocks.0.norm1.weight\n",
      "image_encoder.trunk.blocks.0.norm1.bias\n",
      "image_encoder.trunk.blocks.0.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.0.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.0.attn.proj.weight\n",
      "image_encoder.trunk.blocks.0.attn.proj.bias\n",
      "image_encoder.trunk.blocks.0.norm2.weight\n",
      "image_encoder.trunk.blocks.0.norm2.bias\n",
      "image_encoder.trunk.blocks.0.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.0.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.0.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.0.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.1.norm1.weight\n",
      "image_encoder.trunk.blocks.1.norm1.bias\n",
      "image_encoder.trunk.blocks.1.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.1.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.1.attn.proj.weight\n",
      "image_encoder.trunk.blocks.1.attn.proj.bias\n",
      "image_encoder.trunk.blocks.1.norm2.weight\n",
      "image_encoder.trunk.blocks.1.norm2.bias\n",
      "image_encoder.trunk.blocks.1.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.1.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.1.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.1.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.1.proj.weight\n",
      "image_encoder.trunk.blocks.1.proj.bias\n",
      "image_encoder.trunk.blocks.2.norm1.weight\n",
      "image_encoder.trunk.blocks.2.norm1.bias\n",
      "image_encoder.trunk.blocks.2.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.2.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.2.attn.proj.weight\n",
      "image_encoder.trunk.blocks.2.attn.proj.bias\n",
      "image_encoder.trunk.blocks.2.norm2.weight\n",
      "image_encoder.trunk.blocks.2.norm2.bias\n",
      "image_encoder.trunk.blocks.2.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.2.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.2.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.2.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.3.norm1.weight\n",
      "image_encoder.trunk.blocks.3.norm1.bias\n",
      "image_encoder.trunk.blocks.3.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.3.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.3.attn.proj.weight\n",
      "image_encoder.trunk.blocks.3.attn.proj.bias\n",
      "image_encoder.trunk.blocks.3.norm2.weight\n",
      "image_encoder.trunk.blocks.3.norm2.bias\n",
      "image_encoder.trunk.blocks.3.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.3.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.3.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.3.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.3.proj.weight\n",
      "image_encoder.trunk.blocks.3.proj.bias\n",
      "image_encoder.trunk.blocks.4.norm1.weight\n",
      "image_encoder.trunk.blocks.4.norm1.bias\n",
      "image_encoder.trunk.blocks.4.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.4.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.4.attn.proj.weight\n",
      "image_encoder.trunk.blocks.4.attn.proj.bias\n",
      "image_encoder.trunk.blocks.4.norm2.weight\n",
      "image_encoder.trunk.blocks.4.norm2.bias\n",
      "image_encoder.trunk.blocks.4.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.4.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.4.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.4.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.5.norm1.weight\n",
      "image_encoder.trunk.blocks.5.norm1.bias\n",
      "image_encoder.trunk.blocks.5.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.5.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.5.attn.proj.weight\n",
      "image_encoder.trunk.blocks.5.attn.proj.bias\n",
      "image_encoder.trunk.blocks.5.norm2.weight\n",
      "image_encoder.trunk.blocks.5.norm2.bias\n",
      "image_encoder.trunk.blocks.5.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.5.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.5.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.5.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.6.norm1.weight\n",
      "image_encoder.trunk.blocks.6.norm1.bias\n",
      "image_encoder.trunk.blocks.6.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.6.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.6.attn.proj.weight\n",
      "image_encoder.trunk.blocks.6.attn.proj.bias\n",
      "image_encoder.trunk.blocks.6.norm2.weight\n",
      "image_encoder.trunk.blocks.6.norm2.bias\n",
      "image_encoder.trunk.blocks.6.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.6.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.6.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.6.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.7.norm1.weight\n",
      "image_encoder.trunk.blocks.7.norm1.bias\n",
      "image_encoder.trunk.blocks.7.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.7.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.7.attn.proj.weight\n",
      "image_encoder.trunk.blocks.7.attn.proj.bias\n",
      "image_encoder.trunk.blocks.7.norm2.weight\n",
      "image_encoder.trunk.blocks.7.norm2.bias\n",
      "image_encoder.trunk.blocks.7.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.7.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.7.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.7.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.8.norm1.weight\n",
      "image_encoder.trunk.blocks.8.norm1.bias\n",
      "image_encoder.trunk.blocks.8.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.8.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.8.attn.proj.weight\n",
      "image_encoder.trunk.blocks.8.attn.proj.bias\n",
      "image_encoder.trunk.blocks.8.norm2.weight\n",
      "image_encoder.trunk.blocks.8.norm2.bias\n",
      "image_encoder.trunk.blocks.8.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.8.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.8.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.8.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.9.norm1.weight\n",
      "image_encoder.trunk.blocks.9.norm1.bias\n",
      "image_encoder.trunk.blocks.9.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.9.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.9.attn.proj.weight\n",
      "image_encoder.trunk.blocks.9.attn.proj.bias\n",
      "image_encoder.trunk.blocks.9.norm2.weight\n",
      "image_encoder.trunk.blocks.9.norm2.bias\n",
      "image_encoder.trunk.blocks.9.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.9.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.9.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.9.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.10.norm1.weight\n",
      "image_encoder.trunk.blocks.10.norm1.bias\n",
      "image_encoder.trunk.blocks.10.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.10.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.10.attn.proj.weight\n",
      "image_encoder.trunk.blocks.10.attn.proj.bias\n",
      "image_encoder.trunk.blocks.10.norm2.weight\n",
      "image_encoder.trunk.blocks.10.norm2.bias\n",
      "image_encoder.trunk.blocks.10.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.10.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.10.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.10.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.10.proj.weight\n",
      "image_encoder.trunk.blocks.10.proj.bias\n",
      "image_encoder.trunk.blocks.11.norm1.weight\n",
      "image_encoder.trunk.blocks.11.norm1.bias\n",
      "image_encoder.trunk.blocks.11.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.11.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.11.attn.proj.weight\n",
      "image_encoder.trunk.blocks.11.attn.proj.bias\n",
      "image_encoder.trunk.blocks.11.norm2.weight\n",
      "image_encoder.trunk.blocks.11.norm2.bias\n",
      "image_encoder.trunk.blocks.11.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.11.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.11.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.11.mlp.layers.1.bias\n",
      "image_encoder.neck.convs.0.conv.weight\n",
      "image_encoder.neck.convs.0.conv.bias\n",
      "image_encoder.neck.convs.1.conv.weight\n",
      "image_encoder.neck.convs.1.conv.bias\n",
      "image_encoder.neck.convs.2.conv.weight\n",
      "image_encoder.neck.convs.2.conv.bias\n",
      "image_encoder.neck.convs.3.conv.weight\n",
      "image_encoder.neck.convs.3.conv.bias\n",
      "mask_downsample.weight\n",
      "mask_downsample.bias\n",
      "memory_attention.layers.0.self_attn.q_proj.weight\n",
      "memory_attention.layers.0.self_attn.q_proj.bias\n",
      "memory_attention.layers.0.self_attn.k_proj.weight\n",
      "memory_attention.layers.0.self_attn.k_proj.bias\n",
      "memory_attention.layers.0.self_attn.v_proj.weight\n",
      "memory_attention.layers.0.self_attn.v_proj.bias\n",
      "memory_attention.layers.0.self_attn.out_proj.weight\n",
      "memory_attention.layers.0.self_attn.out_proj.bias\n",
      "memory_attention.layers.0.cross_attn_image.q_proj.weight\n",
      "memory_attention.layers.0.cross_attn_image.q_proj.bias\n",
      "memory_attention.layers.0.cross_attn_image.k_proj.weight\n",
      "memory_attention.layers.0.cross_attn_image.k_proj.bias\n",
      "memory_attention.layers.0.cross_attn_image.v_proj.weight\n",
      "memory_attention.layers.0.cross_attn_image.v_proj.bias\n",
      "memory_attention.layers.0.cross_attn_image.out_proj.weight\n",
      "memory_attention.layers.0.cross_attn_image.out_proj.bias\n",
      "memory_attention.layers.0.linear1.weight\n",
      "memory_attention.layers.0.linear1.bias\n",
      "memory_attention.layers.0.linear2.weight\n",
      "memory_attention.layers.0.linear2.bias\n",
      "memory_attention.layers.0.norm1.weight\n",
      "memory_attention.layers.0.norm1.bias\n",
      "memory_attention.layers.0.norm2.weight\n",
      "memory_attention.layers.0.norm2.bias\n",
      "memory_attention.layers.0.norm3.weight\n",
      "memory_attention.layers.0.norm3.bias\n",
      "memory_attention.layers.1.self_attn.q_proj.weight\n",
      "memory_attention.layers.1.self_attn.q_proj.bias\n",
      "memory_attention.layers.1.self_attn.k_proj.weight\n",
      "memory_attention.layers.1.self_attn.k_proj.bias\n",
      "memory_attention.layers.1.self_attn.v_proj.weight\n",
      "memory_attention.layers.1.self_attn.v_proj.bias\n",
      "memory_attention.layers.1.self_attn.out_proj.weight\n",
      "memory_attention.layers.1.self_attn.out_proj.bias\n",
      "memory_attention.layers.1.cross_attn_image.q_proj.weight\n",
      "memory_attention.layers.1.cross_attn_image.q_proj.bias\n",
      "memory_attention.layers.1.cross_attn_image.k_proj.weight\n",
      "memory_attention.layers.1.cross_attn_image.k_proj.bias\n",
      "memory_attention.layers.1.cross_attn_image.v_proj.weight\n",
      "memory_attention.layers.1.cross_attn_image.v_proj.bias\n",
      "memory_attention.layers.1.cross_attn_image.out_proj.weight\n",
      "memory_attention.layers.1.cross_attn_image.out_proj.bias\n",
      "memory_attention.layers.1.linear1.weight\n",
      "memory_attention.layers.1.linear1.bias\n",
      "memory_attention.layers.1.linear2.weight\n",
      "memory_attention.layers.1.linear2.bias\n",
      "memory_attention.layers.1.norm1.weight\n",
      "memory_attention.layers.1.norm1.bias\n",
      "memory_attention.layers.1.norm2.weight\n",
      "memory_attention.layers.1.norm2.bias\n",
      "memory_attention.layers.1.norm3.weight\n",
      "memory_attention.layers.1.norm3.bias\n",
      "memory_attention.layers.2.self_attn.q_proj.weight\n",
      "memory_attention.layers.2.self_attn.q_proj.bias\n",
      "memory_attention.layers.2.self_attn.k_proj.weight\n",
      "memory_attention.layers.2.self_attn.k_proj.bias\n",
      "memory_attention.layers.2.self_attn.v_proj.weight\n",
      "memory_attention.layers.2.self_attn.v_proj.bias\n",
      "memory_attention.layers.2.self_attn.out_proj.weight\n",
      "memory_attention.layers.2.self_attn.out_proj.bias\n",
      "memory_attention.layers.2.cross_attn_image.q_proj.weight\n",
      "memory_attention.layers.2.cross_attn_image.q_proj.bias\n",
      "memory_attention.layers.2.cross_attn_image.k_proj.weight\n",
      "memory_attention.layers.2.cross_attn_image.k_proj.bias\n",
      "memory_attention.layers.2.cross_attn_image.v_proj.weight\n",
      "memory_attention.layers.2.cross_attn_image.v_proj.bias\n",
      "memory_attention.layers.2.cross_attn_image.out_proj.weight\n",
      "memory_attention.layers.2.cross_attn_image.out_proj.bias\n",
      "memory_attention.layers.2.linear1.weight\n",
      "memory_attention.layers.2.linear1.bias\n",
      "memory_attention.layers.2.linear2.weight\n",
      "memory_attention.layers.2.linear2.bias\n",
      "memory_attention.layers.2.norm1.weight\n",
      "memory_attention.layers.2.norm1.bias\n",
      "memory_attention.layers.2.norm2.weight\n",
      "memory_attention.layers.2.norm2.bias\n",
      "memory_attention.layers.2.norm3.weight\n",
      "memory_attention.layers.2.norm3.bias\n",
      "memory_attention.layers.3.self_attn.q_proj.weight\n",
      "memory_attention.layers.3.self_attn.q_proj.bias\n",
      "memory_attention.layers.3.self_attn.k_proj.weight\n",
      "memory_attention.layers.3.self_attn.k_proj.bias\n",
      "memory_attention.layers.3.self_attn.v_proj.weight\n",
      "memory_attention.layers.3.self_attn.v_proj.bias\n",
      "memory_attention.layers.3.self_attn.out_proj.weight\n",
      "memory_attention.layers.3.self_attn.out_proj.bias\n",
      "memory_attention.layers.3.cross_attn_image.q_proj.weight\n",
      "memory_attention.layers.3.cross_attn_image.q_proj.bias\n",
      "memory_attention.layers.3.cross_attn_image.k_proj.weight\n",
      "memory_attention.layers.3.cross_attn_image.k_proj.bias\n",
      "memory_attention.layers.3.cross_attn_image.v_proj.weight\n",
      "memory_attention.layers.3.cross_attn_image.v_proj.bias\n",
      "memory_attention.layers.3.cross_attn_image.out_proj.weight\n",
      "memory_attention.layers.3.cross_attn_image.out_proj.bias\n",
      "memory_attention.layers.3.linear1.weight\n",
      "memory_attention.layers.3.linear1.bias\n",
      "memory_attention.layers.3.linear2.weight\n",
      "memory_attention.layers.3.linear2.bias\n",
      "memory_attention.layers.3.norm1.weight\n",
      "memory_attention.layers.3.norm1.bias\n",
      "memory_attention.layers.3.norm2.weight\n",
      "memory_attention.layers.3.norm2.bias\n",
      "memory_attention.layers.3.norm3.weight\n",
      "memory_attention.layers.3.norm3.bias\n",
      "memory_attention.norm.weight\n",
      "memory_attention.norm.bias\n",
      "memory_encoder.mask_downsampler.encoder.0.weight\n",
      "memory_encoder.mask_downsampler.encoder.0.bias\n",
      "memory_encoder.mask_downsampler.encoder.1.weight\n",
      "memory_encoder.mask_downsampler.encoder.1.bias\n",
      "memory_encoder.mask_downsampler.encoder.3.weight\n",
      "memory_encoder.mask_downsampler.encoder.3.bias\n",
      "memory_encoder.mask_downsampler.encoder.4.weight\n",
      "memory_encoder.mask_downsampler.encoder.4.bias\n",
      "memory_encoder.mask_downsampler.encoder.6.weight\n",
      "memory_encoder.mask_downsampler.encoder.6.bias\n",
      "memory_encoder.mask_downsampler.encoder.7.weight\n",
      "memory_encoder.mask_downsampler.encoder.7.bias\n",
      "memory_encoder.mask_downsampler.encoder.9.weight\n",
      "memory_encoder.mask_downsampler.encoder.9.bias\n",
      "memory_encoder.mask_downsampler.encoder.10.weight\n",
      "memory_encoder.mask_downsampler.encoder.10.bias\n",
      "memory_encoder.mask_downsampler.encoder.12.weight\n",
      "memory_encoder.mask_downsampler.encoder.12.bias\n",
      "memory_encoder.pix_feat_proj.weight\n",
      "memory_encoder.pix_feat_proj.bias\n",
      "memory_encoder.fuser.layers.0.gamma\n",
      "memory_encoder.fuser.layers.0.dwconv.weight\n",
      "memory_encoder.fuser.layers.0.dwconv.bias\n",
      "memory_encoder.fuser.layers.0.norm.weight\n",
      "memory_encoder.fuser.layers.0.norm.bias\n",
      "memory_encoder.fuser.layers.0.pwconv1.weight\n",
      "memory_encoder.fuser.layers.0.pwconv1.bias\n",
      "memory_encoder.fuser.layers.0.pwconv2.weight\n",
      "memory_encoder.fuser.layers.0.pwconv2.bias\n",
      "memory_encoder.fuser.layers.1.gamma\n",
      "memory_encoder.fuser.layers.1.dwconv.weight\n",
      "memory_encoder.fuser.layers.1.dwconv.bias\n",
      "memory_encoder.fuser.layers.1.norm.weight\n",
      "memory_encoder.fuser.layers.1.norm.bias\n",
      "memory_encoder.fuser.layers.1.pwconv1.weight\n",
      "memory_encoder.fuser.layers.1.pwconv1.bias\n",
      "memory_encoder.fuser.layers.1.pwconv2.weight\n",
      "memory_encoder.fuser.layers.1.pwconv2.bias\n",
      "memory_encoder.out_proj.weight\n",
      "memory_encoder.out_proj.bias\n",
      "sam_prompt_encoder.pe_layer.positional_encoding_gaussian_matrix\n",
      "sam_prompt_encoder.point_embeddings.0.weight\n",
      "sam_prompt_encoder.point_embeddings.1.weight\n",
      "sam_prompt_encoder.point_embeddings.2.weight\n",
      "sam_prompt_encoder.point_embeddings.3.weight\n",
      "sam_prompt_encoder.not_a_point_embed.weight\n",
      "sam_prompt_encoder.mask_downscaling.0.weight\n",
      "sam_prompt_encoder.mask_downscaling.0.bias\n",
      "sam_prompt_encoder.mask_downscaling.1.weight\n",
      "sam_prompt_encoder.mask_downscaling.1.bias\n",
      "sam_prompt_encoder.mask_downscaling.3.weight\n",
      "sam_prompt_encoder.mask_downscaling.3.bias\n",
      "sam_prompt_encoder.mask_downscaling.4.weight\n",
      "sam_prompt_encoder.mask_downscaling.4.bias\n",
      "sam_prompt_encoder.mask_downscaling.6.weight\n",
      "sam_prompt_encoder.mask_downscaling.6.bias\n",
      "sam_prompt_encoder.no_mask_embed.weight\n",
      "sam_mask_decoder.transformer.layers.0.self_attn.q_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.self_attn.k_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.self_attn.v_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.self_attn.out_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.norm1.weight\n",
      "sam_mask_decoder.transformer.layers.0.norm1.bias\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.norm2.weight\n",
      "sam_mask_decoder.transformer.layers.0.norm2.bias\n",
      "sam_mask_decoder.transformer.layers.0.mlp.layers.0.weight\n",
      "sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias\n",
      "sam_mask_decoder.transformer.layers.0.mlp.layers.1.weight\n",
      "sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias\n",
      "sam_mask_decoder.transformer.layers.0.norm3.weight\n",
      "sam_mask_decoder.transformer.layers.0.norm3.bias\n",
      "sam_mask_decoder.transformer.layers.0.norm4.weight\n",
      "sam_mask_decoder.transformer.layers.0.norm4.bias\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.self_attn.q_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.self_attn.k_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.self_attn.v_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.self_attn.out_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.norm1.weight\n",
      "sam_mask_decoder.transformer.layers.1.norm1.bias\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.norm2.weight\n",
      "sam_mask_decoder.transformer.layers.1.norm2.bias\n",
      "sam_mask_decoder.transformer.layers.1.mlp.layers.0.weight\n",
      "sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias\n",
      "sam_mask_decoder.transformer.layers.1.mlp.layers.1.weight\n",
      "sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias\n",
      "sam_mask_decoder.transformer.layers.1.norm3.weight\n",
      "sam_mask_decoder.transformer.layers.1.norm3.bias\n",
      "sam_mask_decoder.transformer.layers.1.norm4.weight\n",
      "sam_mask_decoder.transformer.layers.1.norm4.bias\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias\n",
      "sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.weight\n",
      "sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias\n",
      "sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.weight\n",
      "sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias\n",
      "sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.weight\n",
      "sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias\n",
      "sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.weight\n",
      "sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias\n",
      "sam_mask_decoder.transformer.norm_final_attn.weight\n",
      "sam_mask_decoder.transformer.norm_final_attn.bias\n",
      "sam_mask_decoder.iou_token.weight\n",
      "sam_mask_decoder.mask_tokens.weight\n",
      "sam_mask_decoder.obj_score_token.weight\n",
      "sam_mask_decoder.output_upscaling.0.weight\n",
      "sam_mask_decoder.output_upscaling.0.bias\n",
      "sam_mask_decoder.output_upscaling.1.weight\n",
      "sam_mask_decoder.output_upscaling.1.bias\n",
      "sam_mask_decoder.output_upscaling.3.weight\n",
      "sam_mask_decoder.output_upscaling.3.bias\n",
      "sam_mask_decoder.conv_s0.weight\n",
      "sam_mask_decoder.conv_s0.bias\n",
      "sam_mask_decoder.conv_s1.weight\n",
      "sam_mask_decoder.conv_s1.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias\n",
      "sam_mask_decoder.iou_prediction_head.layers.0.weight\n",
      "sam_mask_decoder.iou_prediction_head.layers.0.bias\n",
      "sam_mask_decoder.iou_prediction_head.layers.1.weight\n",
      "sam_mask_decoder.iou_prediction_head.layers.1.bias\n",
      "sam_mask_decoder.iou_prediction_head.layers.2.weight\n",
      "sam_mask_decoder.iou_prediction_head.layers.2.bias\n",
      "sam_mask_decoder.pred_obj_score_head.layers.0.weight\n",
      "sam_mask_decoder.pred_obj_score_head.layers.0.bias\n",
      "sam_mask_decoder.pred_obj_score_head.layers.1.weight\n",
      "sam_mask_decoder.pred_obj_score_head.layers.1.bias\n",
      "sam_mask_decoder.pred_obj_score_head.layers.2.weight\n",
      "sam_mask_decoder.pred_obj_score_head.layers.2.bias\n",
      "obj_ptr_proj.layers.0.weight\n",
      "obj_ptr_proj.layers.0.bias\n",
      "obj_ptr_proj.layers.1.weight\n",
      "obj_ptr_proj.layers.1.bias\n",
      "obj_ptr_proj.layers.2.weight\n",
      "obj_ptr_proj.layers.2.bias\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ckpt = torch.load(\"checkpoints/sam2_hiera_tiny.pt\")\n",
    "for k in ckpt[\"model\"].keys(): print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0837f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2652],\n",
       "        [0.9207],\n",
       "        [0.0419],\n",
       "        [0.8765],\n",
       "        [0.2967],\n",
       "        [0.1186],\n",
       "        [0.1222],\n",
       "        [0.2329]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "param = nn.Parameter(torch.Tensor([0]))\n",
    "optimizer = torch.optim.AdamW(param, lr=)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=5, last_epoch=15)\n",
    "\n",
    "for ep in range(30):\n",
    "    scheduler.step()\n",
    "    print(scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71944817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2\n",
      "1 3 4\n",
      "2 5 6\n",
      "3 7 8\n"
     ]
    }
   ],
   "source": [
    "for i, (a, b) in enumerate(zip([1,3,5,7], [2,4,6,8])):\n",
    "    print(i, a, b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
