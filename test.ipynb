{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19c1fc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maskmem_tpos_enc\n",
      "no_mem_embed\n",
      "no_mem_pos_enc\n",
      "no_obj_ptr\n",
      "image_encoder.trunk.pos_embed\n",
      "image_encoder.trunk.pos_embed_window\n",
      "image_encoder.trunk.patch_embed.proj.weight\n",
      "image_encoder.trunk.patch_embed.proj.bias\n",
      "image_encoder.trunk.blocks.0.norm1.weight\n",
      "image_encoder.trunk.blocks.0.norm1.bias\n",
      "image_encoder.trunk.blocks.0.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.0.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.0.attn.proj.weight\n",
      "image_encoder.trunk.blocks.0.attn.proj.bias\n",
      "image_encoder.trunk.blocks.0.norm2.weight\n",
      "image_encoder.trunk.blocks.0.norm2.bias\n",
      "image_encoder.trunk.blocks.0.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.0.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.0.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.0.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.1.norm1.weight\n",
      "image_encoder.trunk.blocks.1.norm1.bias\n",
      "image_encoder.trunk.blocks.1.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.1.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.1.attn.proj.weight\n",
      "image_encoder.trunk.blocks.1.attn.proj.bias\n",
      "image_encoder.trunk.blocks.1.norm2.weight\n",
      "image_encoder.trunk.blocks.1.norm2.bias\n",
      "image_encoder.trunk.blocks.1.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.1.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.1.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.1.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.1.proj.weight\n",
      "image_encoder.trunk.blocks.1.proj.bias\n",
      "image_encoder.trunk.blocks.2.norm1.weight\n",
      "image_encoder.trunk.blocks.2.norm1.bias\n",
      "image_encoder.trunk.blocks.2.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.2.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.2.attn.proj.weight\n",
      "image_encoder.trunk.blocks.2.attn.proj.bias\n",
      "image_encoder.trunk.blocks.2.norm2.weight\n",
      "image_encoder.trunk.blocks.2.norm2.bias\n",
      "image_encoder.trunk.blocks.2.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.2.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.2.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.2.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.3.norm1.weight\n",
      "image_encoder.trunk.blocks.3.norm1.bias\n",
      "image_encoder.trunk.blocks.3.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.3.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.3.attn.proj.weight\n",
      "image_encoder.trunk.blocks.3.attn.proj.bias\n",
      "image_encoder.trunk.blocks.3.norm2.weight\n",
      "image_encoder.trunk.blocks.3.norm2.bias\n",
      "image_encoder.trunk.blocks.3.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.3.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.3.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.3.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.3.proj.weight\n",
      "image_encoder.trunk.blocks.3.proj.bias\n",
      "image_encoder.trunk.blocks.4.norm1.weight\n",
      "image_encoder.trunk.blocks.4.norm1.bias\n",
      "image_encoder.trunk.blocks.4.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.4.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.4.attn.proj.weight\n",
      "image_encoder.trunk.blocks.4.attn.proj.bias\n",
      "image_encoder.trunk.blocks.4.norm2.weight\n",
      "image_encoder.trunk.blocks.4.norm2.bias\n",
      "image_encoder.trunk.blocks.4.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.4.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.4.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.4.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.5.norm1.weight\n",
      "image_encoder.trunk.blocks.5.norm1.bias\n",
      "image_encoder.trunk.blocks.5.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.5.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.5.attn.proj.weight\n",
      "image_encoder.trunk.blocks.5.attn.proj.bias\n",
      "image_encoder.trunk.blocks.5.norm2.weight\n",
      "image_encoder.trunk.blocks.5.norm2.bias\n",
      "image_encoder.trunk.blocks.5.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.5.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.5.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.5.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.6.norm1.weight\n",
      "image_encoder.trunk.blocks.6.norm1.bias\n",
      "image_encoder.trunk.blocks.6.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.6.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.6.attn.proj.weight\n",
      "image_encoder.trunk.blocks.6.attn.proj.bias\n",
      "image_encoder.trunk.blocks.6.norm2.weight\n",
      "image_encoder.trunk.blocks.6.norm2.bias\n",
      "image_encoder.trunk.blocks.6.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.6.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.6.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.6.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.7.norm1.weight\n",
      "image_encoder.trunk.blocks.7.norm1.bias\n",
      "image_encoder.trunk.blocks.7.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.7.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.7.attn.proj.weight\n",
      "image_encoder.trunk.blocks.7.attn.proj.bias\n",
      "image_encoder.trunk.blocks.7.norm2.weight\n",
      "image_encoder.trunk.blocks.7.norm2.bias\n",
      "image_encoder.trunk.blocks.7.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.7.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.7.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.7.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.8.norm1.weight\n",
      "image_encoder.trunk.blocks.8.norm1.bias\n",
      "image_encoder.trunk.blocks.8.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.8.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.8.attn.proj.weight\n",
      "image_encoder.trunk.blocks.8.attn.proj.bias\n",
      "image_encoder.trunk.blocks.8.norm2.weight\n",
      "image_encoder.trunk.blocks.8.norm2.bias\n",
      "image_encoder.trunk.blocks.8.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.8.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.8.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.8.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.9.norm1.weight\n",
      "image_encoder.trunk.blocks.9.norm1.bias\n",
      "image_encoder.trunk.blocks.9.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.9.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.9.attn.proj.weight\n",
      "image_encoder.trunk.blocks.9.attn.proj.bias\n",
      "image_encoder.trunk.blocks.9.norm2.weight\n",
      "image_encoder.trunk.blocks.9.norm2.bias\n",
      "image_encoder.trunk.blocks.9.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.9.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.9.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.9.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.10.norm1.weight\n",
      "image_encoder.trunk.blocks.10.norm1.bias\n",
      "image_encoder.trunk.blocks.10.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.10.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.10.attn.proj.weight\n",
      "image_encoder.trunk.blocks.10.attn.proj.bias\n",
      "image_encoder.trunk.blocks.10.norm2.weight\n",
      "image_encoder.trunk.blocks.10.norm2.bias\n",
      "image_encoder.trunk.blocks.10.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.10.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.10.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.10.mlp.layers.1.bias\n",
      "image_encoder.trunk.blocks.10.proj.weight\n",
      "image_encoder.trunk.blocks.10.proj.bias\n",
      "image_encoder.trunk.blocks.11.norm1.weight\n",
      "image_encoder.trunk.blocks.11.norm1.bias\n",
      "image_encoder.trunk.blocks.11.attn.qkv.weight\n",
      "image_encoder.trunk.blocks.11.attn.qkv.bias\n",
      "image_encoder.trunk.blocks.11.attn.proj.weight\n",
      "image_encoder.trunk.blocks.11.attn.proj.bias\n",
      "image_encoder.trunk.blocks.11.norm2.weight\n",
      "image_encoder.trunk.blocks.11.norm2.bias\n",
      "image_encoder.trunk.blocks.11.mlp.layers.0.weight\n",
      "image_encoder.trunk.blocks.11.mlp.layers.0.bias\n",
      "image_encoder.trunk.blocks.11.mlp.layers.1.weight\n",
      "image_encoder.trunk.blocks.11.mlp.layers.1.bias\n",
      "image_encoder.neck.convs.0.conv.weight\n",
      "image_encoder.neck.convs.0.conv.bias\n",
      "image_encoder.neck.convs.1.conv.weight\n",
      "image_encoder.neck.convs.1.conv.bias\n",
      "image_encoder.neck.convs.2.conv.weight\n",
      "image_encoder.neck.convs.2.conv.bias\n",
      "image_encoder.neck.convs.3.conv.weight\n",
      "image_encoder.neck.convs.3.conv.bias\n",
      "mask_downsample.weight\n",
      "mask_downsample.bias\n",
      "memory_attention.layers.0.self_attn.q_proj.weight\n",
      "memory_attention.layers.0.self_attn.q_proj.bias\n",
      "memory_attention.layers.0.self_attn.k_proj.weight\n",
      "memory_attention.layers.0.self_attn.k_proj.bias\n",
      "memory_attention.layers.0.self_attn.v_proj.weight\n",
      "memory_attention.layers.0.self_attn.v_proj.bias\n",
      "memory_attention.layers.0.self_attn.out_proj.weight\n",
      "memory_attention.layers.0.self_attn.out_proj.bias\n",
      "memory_attention.layers.0.cross_attn_image.q_proj.weight\n",
      "memory_attention.layers.0.cross_attn_image.q_proj.bias\n",
      "memory_attention.layers.0.cross_attn_image.k_proj.weight\n",
      "memory_attention.layers.0.cross_attn_image.k_proj.bias\n",
      "memory_attention.layers.0.cross_attn_image.v_proj.weight\n",
      "memory_attention.layers.0.cross_attn_image.v_proj.bias\n",
      "memory_attention.layers.0.cross_attn_image.out_proj.weight\n",
      "memory_attention.layers.0.cross_attn_image.out_proj.bias\n",
      "memory_attention.layers.0.linear1.weight\n",
      "memory_attention.layers.0.linear1.bias\n",
      "memory_attention.layers.0.linear2.weight\n",
      "memory_attention.layers.0.linear2.bias\n",
      "memory_attention.layers.0.norm1.weight\n",
      "memory_attention.layers.0.norm1.bias\n",
      "memory_attention.layers.0.norm2.weight\n",
      "memory_attention.layers.0.norm2.bias\n",
      "memory_attention.layers.0.norm3.weight\n",
      "memory_attention.layers.0.norm3.bias\n",
      "memory_attention.layers.1.self_attn.q_proj.weight\n",
      "memory_attention.layers.1.self_attn.q_proj.bias\n",
      "memory_attention.layers.1.self_attn.k_proj.weight\n",
      "memory_attention.layers.1.self_attn.k_proj.bias\n",
      "memory_attention.layers.1.self_attn.v_proj.weight\n",
      "memory_attention.layers.1.self_attn.v_proj.bias\n",
      "memory_attention.layers.1.self_attn.out_proj.weight\n",
      "memory_attention.layers.1.self_attn.out_proj.bias\n",
      "memory_attention.layers.1.cross_attn_image.q_proj.weight\n",
      "memory_attention.layers.1.cross_attn_image.q_proj.bias\n",
      "memory_attention.layers.1.cross_attn_image.k_proj.weight\n",
      "memory_attention.layers.1.cross_attn_image.k_proj.bias\n",
      "memory_attention.layers.1.cross_attn_image.v_proj.weight\n",
      "memory_attention.layers.1.cross_attn_image.v_proj.bias\n",
      "memory_attention.layers.1.cross_attn_image.out_proj.weight\n",
      "memory_attention.layers.1.cross_attn_image.out_proj.bias\n",
      "memory_attention.layers.1.linear1.weight\n",
      "memory_attention.layers.1.linear1.bias\n",
      "memory_attention.layers.1.linear2.weight\n",
      "memory_attention.layers.1.linear2.bias\n",
      "memory_attention.layers.1.norm1.weight\n",
      "memory_attention.layers.1.norm1.bias\n",
      "memory_attention.layers.1.norm2.weight\n",
      "memory_attention.layers.1.norm2.bias\n",
      "memory_attention.layers.1.norm3.weight\n",
      "memory_attention.layers.1.norm3.bias\n",
      "memory_attention.layers.2.self_attn.q_proj.weight\n",
      "memory_attention.layers.2.self_attn.q_proj.bias\n",
      "memory_attention.layers.2.self_attn.k_proj.weight\n",
      "memory_attention.layers.2.self_attn.k_proj.bias\n",
      "memory_attention.layers.2.self_attn.v_proj.weight\n",
      "memory_attention.layers.2.self_attn.v_proj.bias\n",
      "memory_attention.layers.2.self_attn.out_proj.weight\n",
      "memory_attention.layers.2.self_attn.out_proj.bias\n",
      "memory_attention.layers.2.cross_attn_image.q_proj.weight\n",
      "memory_attention.layers.2.cross_attn_image.q_proj.bias\n",
      "memory_attention.layers.2.cross_attn_image.k_proj.weight\n",
      "memory_attention.layers.2.cross_attn_image.k_proj.bias\n",
      "memory_attention.layers.2.cross_attn_image.v_proj.weight\n",
      "memory_attention.layers.2.cross_attn_image.v_proj.bias\n",
      "memory_attention.layers.2.cross_attn_image.out_proj.weight\n",
      "memory_attention.layers.2.cross_attn_image.out_proj.bias\n",
      "memory_attention.layers.2.linear1.weight\n",
      "memory_attention.layers.2.linear1.bias\n",
      "memory_attention.layers.2.linear2.weight\n",
      "memory_attention.layers.2.linear2.bias\n",
      "memory_attention.layers.2.norm1.weight\n",
      "memory_attention.layers.2.norm1.bias\n",
      "memory_attention.layers.2.norm2.weight\n",
      "memory_attention.layers.2.norm2.bias\n",
      "memory_attention.layers.2.norm3.weight\n",
      "memory_attention.layers.2.norm3.bias\n",
      "memory_attention.layers.3.self_attn.q_proj.weight\n",
      "memory_attention.layers.3.self_attn.q_proj.bias\n",
      "memory_attention.layers.3.self_attn.k_proj.weight\n",
      "memory_attention.layers.3.self_attn.k_proj.bias\n",
      "memory_attention.layers.3.self_attn.v_proj.weight\n",
      "memory_attention.layers.3.self_attn.v_proj.bias\n",
      "memory_attention.layers.3.self_attn.out_proj.weight\n",
      "memory_attention.layers.3.self_attn.out_proj.bias\n",
      "memory_attention.layers.3.cross_attn_image.q_proj.weight\n",
      "memory_attention.layers.3.cross_attn_image.q_proj.bias\n",
      "memory_attention.layers.3.cross_attn_image.k_proj.weight\n",
      "memory_attention.layers.3.cross_attn_image.k_proj.bias\n",
      "memory_attention.layers.3.cross_attn_image.v_proj.weight\n",
      "memory_attention.layers.3.cross_attn_image.v_proj.bias\n",
      "memory_attention.layers.3.cross_attn_image.out_proj.weight\n",
      "memory_attention.layers.3.cross_attn_image.out_proj.bias\n",
      "memory_attention.layers.3.linear1.weight\n",
      "memory_attention.layers.3.linear1.bias\n",
      "memory_attention.layers.3.linear2.weight\n",
      "memory_attention.layers.3.linear2.bias\n",
      "memory_attention.layers.3.norm1.weight\n",
      "memory_attention.layers.3.norm1.bias\n",
      "memory_attention.layers.3.norm2.weight\n",
      "memory_attention.layers.3.norm2.bias\n",
      "memory_attention.layers.3.norm3.weight\n",
      "memory_attention.layers.3.norm3.bias\n",
      "memory_attention.norm.weight\n",
      "memory_attention.norm.bias\n",
      "memory_encoder.mask_downsampler.encoder.0.weight\n",
      "memory_encoder.mask_downsampler.encoder.0.bias\n",
      "memory_encoder.mask_downsampler.encoder.1.weight\n",
      "memory_encoder.mask_downsampler.encoder.1.bias\n",
      "memory_encoder.mask_downsampler.encoder.3.weight\n",
      "memory_encoder.mask_downsampler.encoder.3.bias\n",
      "memory_encoder.mask_downsampler.encoder.4.weight\n",
      "memory_encoder.mask_downsampler.encoder.4.bias\n",
      "memory_encoder.mask_downsampler.encoder.6.weight\n",
      "memory_encoder.mask_downsampler.encoder.6.bias\n",
      "memory_encoder.mask_downsampler.encoder.7.weight\n",
      "memory_encoder.mask_downsampler.encoder.7.bias\n",
      "memory_encoder.mask_downsampler.encoder.9.weight\n",
      "memory_encoder.mask_downsampler.encoder.9.bias\n",
      "memory_encoder.mask_downsampler.encoder.10.weight\n",
      "memory_encoder.mask_downsampler.encoder.10.bias\n",
      "memory_encoder.mask_downsampler.encoder.12.weight\n",
      "memory_encoder.mask_downsampler.encoder.12.bias\n",
      "memory_encoder.pix_feat_proj.weight\n",
      "memory_encoder.pix_feat_proj.bias\n",
      "memory_encoder.fuser.layers.0.gamma\n",
      "memory_encoder.fuser.layers.0.dwconv.weight\n",
      "memory_encoder.fuser.layers.0.dwconv.bias\n",
      "memory_encoder.fuser.layers.0.norm.weight\n",
      "memory_encoder.fuser.layers.0.norm.bias\n",
      "memory_encoder.fuser.layers.0.pwconv1.weight\n",
      "memory_encoder.fuser.layers.0.pwconv1.bias\n",
      "memory_encoder.fuser.layers.0.pwconv2.weight\n",
      "memory_encoder.fuser.layers.0.pwconv2.bias\n",
      "memory_encoder.fuser.layers.1.gamma\n",
      "memory_encoder.fuser.layers.1.dwconv.weight\n",
      "memory_encoder.fuser.layers.1.dwconv.bias\n",
      "memory_encoder.fuser.layers.1.norm.weight\n",
      "memory_encoder.fuser.layers.1.norm.bias\n",
      "memory_encoder.fuser.layers.1.pwconv1.weight\n",
      "memory_encoder.fuser.layers.1.pwconv1.bias\n",
      "memory_encoder.fuser.layers.1.pwconv2.weight\n",
      "memory_encoder.fuser.layers.1.pwconv2.bias\n",
      "memory_encoder.out_proj.weight\n",
      "memory_encoder.out_proj.bias\n",
      "sam_prompt_encoder.pe_layer.positional_encoding_gaussian_matrix\n",
      "sam_prompt_encoder.point_embeddings.0.weight\n",
      "sam_prompt_encoder.point_embeddings.1.weight\n",
      "sam_prompt_encoder.point_embeddings.2.weight\n",
      "sam_prompt_encoder.point_embeddings.3.weight\n",
      "sam_prompt_encoder.not_a_point_embed.weight\n",
      "sam_prompt_encoder.mask_downscaling.0.weight\n",
      "sam_prompt_encoder.mask_downscaling.0.bias\n",
      "sam_prompt_encoder.mask_downscaling.1.weight\n",
      "sam_prompt_encoder.mask_downscaling.1.bias\n",
      "sam_prompt_encoder.mask_downscaling.3.weight\n",
      "sam_prompt_encoder.mask_downscaling.3.bias\n",
      "sam_prompt_encoder.mask_downscaling.4.weight\n",
      "sam_prompt_encoder.mask_downscaling.4.bias\n",
      "sam_prompt_encoder.mask_downscaling.6.weight\n",
      "sam_prompt_encoder.mask_downscaling.6.bias\n",
      "sam_prompt_encoder.no_mask_embed.weight\n",
      "sam_mask_decoder.transformer.layers.0.self_attn.q_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.self_attn.k_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.self_attn.v_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.self_attn.out_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.norm1.weight\n",
      "sam_mask_decoder.transformer.layers.0.norm1.bias\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.norm2.weight\n",
      "sam_mask_decoder.transformer.layers.0.norm2.bias\n",
      "sam_mask_decoder.transformer.layers.0.mlp.layers.0.weight\n",
      "sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias\n",
      "sam_mask_decoder.transformer.layers.0.mlp.layers.1.weight\n",
      "sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias\n",
      "sam_mask_decoder.transformer.layers.0.norm3.weight\n",
      "sam_mask_decoder.transformer.layers.0.norm3.bias\n",
      "sam_mask_decoder.transformer.layers.0.norm4.weight\n",
      "sam_mask_decoder.transformer.layers.0.norm4.bias\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.weight\n",
      "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.self_attn.q_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.self_attn.k_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.self_attn.v_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.self_attn.out_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.norm1.weight\n",
      "sam_mask_decoder.transformer.layers.1.norm1.bias\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.norm2.weight\n",
      "sam_mask_decoder.transformer.layers.1.norm2.bias\n",
      "sam_mask_decoder.transformer.layers.1.mlp.layers.0.weight\n",
      "sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias\n",
      "sam_mask_decoder.transformer.layers.1.mlp.layers.1.weight\n",
      "sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias\n",
      "sam_mask_decoder.transformer.layers.1.norm3.weight\n",
      "sam_mask_decoder.transformer.layers.1.norm3.bias\n",
      "sam_mask_decoder.transformer.layers.1.norm4.weight\n",
      "sam_mask_decoder.transformer.layers.1.norm4.bias\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.weight\n",
      "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias\n",
      "sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.weight\n",
      "sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias\n",
      "sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.weight\n",
      "sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias\n",
      "sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.weight\n",
      "sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias\n",
      "sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.weight\n",
      "sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias\n",
      "sam_mask_decoder.transformer.norm_final_attn.weight\n",
      "sam_mask_decoder.transformer.norm_final_attn.bias\n",
      "sam_mask_decoder.iou_token.weight\n",
      "sam_mask_decoder.mask_tokens.weight\n",
      "sam_mask_decoder.obj_score_token.weight\n",
      "sam_mask_decoder.output_upscaling.0.weight\n",
      "sam_mask_decoder.output_upscaling.0.bias\n",
      "sam_mask_decoder.output_upscaling.1.weight\n",
      "sam_mask_decoder.output_upscaling.1.bias\n",
      "sam_mask_decoder.output_upscaling.3.weight\n",
      "sam_mask_decoder.output_upscaling.3.bias\n",
      "sam_mask_decoder.conv_s0.weight\n",
      "sam_mask_decoder.conv_s0.bias\n",
      "sam_mask_decoder.conv_s1.weight\n",
      "sam_mask_decoder.conv_s1.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias\n",
      "sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.weight\n",
      "sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias\n",
      "sam_mask_decoder.iou_prediction_head.layers.0.weight\n",
      "sam_mask_decoder.iou_prediction_head.layers.0.bias\n",
      "sam_mask_decoder.iou_prediction_head.layers.1.weight\n",
      "sam_mask_decoder.iou_prediction_head.layers.1.bias\n",
      "sam_mask_decoder.iou_prediction_head.layers.2.weight\n",
      "sam_mask_decoder.iou_prediction_head.layers.2.bias\n",
      "sam_mask_decoder.pred_obj_score_head.layers.0.weight\n",
      "sam_mask_decoder.pred_obj_score_head.layers.0.bias\n",
      "sam_mask_decoder.pred_obj_score_head.layers.1.weight\n",
      "sam_mask_decoder.pred_obj_score_head.layers.1.bias\n",
      "sam_mask_decoder.pred_obj_score_head.layers.2.weight\n",
      "sam_mask_decoder.pred_obj_score_head.layers.2.bias\n",
      "obj_ptr_proj.layers.0.weight\n",
      "obj_ptr_proj.layers.0.bias\n",
      "obj_ptr_proj.layers.1.weight\n",
      "obj_ptr_proj.layers.1.bias\n",
      "obj_ptr_proj.layers.2.weight\n",
      "obj_ptr_proj.layers.2.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1037832/2579334622.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(\"/data/code/DQN-MedSAM2/checkpoints/sam2_hiera_tiny.pt\", map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ckpt = torch.load(\"/data/code/DQN-MedSAM2/checkpoints/sam2_hiera_tiny.pt\", map_location=\"cpu\")\n",
    "for k in ckpt[\"model\"].keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f81c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "for task in glob(f\"/data/datasets/Combined_Dataset/MSD/*\"):\n",
    "    print(task, len(glob(f\"{task}/imagesTr/*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f1b702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68efff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial memory usage: 431.23 MiB\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot handle fancy indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m pos_slices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(data_seg_3d, axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     35\u001b[0m image_3d \u001b[38;5;241m=\u001b[39m image_3d[:, :, pos_slices]\n\u001b[0;32m---> 36\u001b[0m data_seg_3d \u001b[38;5;241m=\u001b[39m \u001b[43mdata_seg_3d\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_slices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     38\u001b[0m max_slices \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image_3d\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m max_slices \u001b[38;5;129;01mand\u001b[39;00m max_slices \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/nibabel/arrayproxy.py:463\u001b[0m, in \u001b[0;36mArrayProxy.__getitem__\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, slicer):\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_scaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslicer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/nibabel/arrayproxy.py:424\u001b[0m, in \u001b[0;36mArrayProxy._get_scaled\u001b[0;34m(self, dtype, slicer)\u001b[0m\n\u001b[1;32m    422\u001b[0m     scl_inter \u001b[38;5;241m=\u001b[39m scl_inter\u001b[38;5;241m.\u001b[39mastype(use_dtype)\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# Read array and upcast as necessary for big slopes, intercepts\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m scaled \u001b[38;5;241m=\u001b[39m apply_read_scaling(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_unscaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslicer\u001b[49m\u001b[43m)\u001b[49m, scl_slope, scl_inter)\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m     scaled \u001b[38;5;241m=\u001b[39m scaled\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mpromote_types(scaled\u001b[38;5;241m.\u001b[39mdtype, dtype), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/nibabel/arrayproxy.py:390\u001b[0m, in \u001b[0;36mArrayProxy._get_unscaled\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_unscaled\u001b[39m(\u001b[38;5;28mself\u001b[39m, slicer):\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcanonical_slicers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslicer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m canonical_slicers(\n\u001b[1;32m    391\u001b[0m         (), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    392\u001b[0m     ):\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    394\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m array_from_file(\n\u001b[1;32m    395\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape,\n\u001b[1;32m    396\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m                 mmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mmap,\n\u001b[1;32m    401\u001b[0m             )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/nibabel/fileslice.py:94\u001b[0m, in \u001b[0;36mcanonical_slicers\u001b[0;34m(sliceobj, shape, check_inds)\u001b[0m\n\u001b[1;32m     92\u001b[0m     sliceobj \u001b[38;5;241m=\u001b[39m (sliceobj,)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_fancy(sliceobj):\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot handle fancy indexing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     95\u001b[0m can_slicers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     96\u001b[0m n_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(shape)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot handle fancy indexing"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import psutil\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "def normalization(image):\n",
    "    image_min = np.min(image)\n",
    "    image_max = np.max(image)\n",
    "    image = ((image - image_min)/(image_max-image_min))*255\n",
    "    return image\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "mem_info = process.memory_info()\n",
    "print(f\"Initial memory usage: {mem_info.rss / (1024 * 1024):.2f} MiB\")\n",
    "\n",
    "image_3d = nib.load(\"/data/datasets/Combined_Dataset/MSD/Task01_BrainTumour/imagesTr/BRATS_433.nii.gz\")\n",
    "data_seg_3d = nib.load(\"/data/datasets/Combined_Dataset/MSD/Task01_BrainTumour/labelsTr/BRATS_433.nii.gz\")\n",
    "image_3d = image_3d.dataobj\n",
    "data_seg_3d = data_seg_3d.dataobj\n",
    "# image_3d = image_3d.get_fdata(dtype=np.float32)\n",
    "# data_seg_3d = data_seg_3d.get_fdata(dtype=np.float32)\n",
    "\n",
    "if image_3d.ndim == 4:\n",
    "    if image_3d.shape[-1] == 4:\n",
    "        image_3d = image_3d[..., 2]\n",
    "    elif image_3d.shape[-1] == 2:\n",
    "        image_3d = image_3d[..., 0]\n",
    "        \n",
    "image_3d = np.asanyarray(image_3d)\n",
    "data_seg_3d = np.asanyarray(data_seg_3d)\n",
    "\n",
    "pos_slices = np.sum(data_seg_3d, axis=(0,1)) > 0\n",
    "image_3d = image_3d[:, :, pos_slices]\n",
    "data_seg_3d = data_seg_3d[:, :, pos_slices]\n",
    "\n",
    "max_slices = 16\n",
    "if image_3d.shape[-1] > max_slices and max_slices > 0:\n",
    "    start_slice = np.random.choice(range(image_3d.shape[-1] - max_slices + 1))\n",
    "    image_3d = image_3d[..., start_slice:start_slice+max_slices]\n",
    "    data_seg_3d = data_seg_3d[..., start_slice:start_slice+max_slices]\n",
    "\n",
    "image_3d = normalization(image_3d)\n",
    "image_3d = torch.rot90(torch.tensor(image_3d)).permute(2, 0, 1).unsqueeze(0).unsqueeze(0)\n",
    "data_seg_3d = torch.rot90(torch.tensor(data_seg_3d)).permute(2, 0, 1).unsqueeze(0).unsqueeze(0)\n",
    "# image_3d = torch.tensor(image_3d).permute(2, 0, 1).unsqueeze(0).unsqueeze(0)\n",
    "# data_seg_3d = torch.tensor(data_seg_3d).permute(2, 0, 1).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "image_3d = F.interpolate(image_3d, size=(image_3d.shape[2], 1024, 1024), mode='trilinear', align_corners=False)\n",
    "data_seg_3d = F.interpolate(data_seg_3d, size=(data_seg_3d.shape[2], 1024, 1024), mode='nearest')\n",
    "image_3d = image_3d.squeeze(0).repeat(3, 1, 1, 1).permute(1, 0, 2, 3)\n",
    "data_seg_3d = data_seg_3d.squeeze(0).squeeze(0)\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "mem_info = process.memory_info()\n",
    "print(f\"Final memory usage: {mem_info.rss / (1024 * 1024):.2f} MiB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
